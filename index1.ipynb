{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status value counts:\n",
      "C     10179\n",
      "D      4482\n",
      "CL      339\n",
      "Name: Status, dtype: int64\n",
      "Best Log Loss: 0.30101947081748326\n",
      "Predictions saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load training and test datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Display value counts for the 'Status' column in the training dataset\n",
    "print(\"Status value counts:\")\n",
    "print(train_df['Status'].value_counts())\n",
    "\n",
    "# Function to preprocess data (handles missing values, encoding, and scaling)\n",
    "def preprocess_data(df, is_train=True):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert categorical variables to numeric values\n",
    "    categorical_cols = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        # Fill missing categorical values with mode or a placeholder\n",
    "        df[col] = df[col].fillna(df[col].mode()[0] if len(df[col].dropna()) > 0 else 'Missing')\n",
    "        # Encode categorical values as numeric\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "    # List of numeric columns to process\n",
    "    numeric_cols = ['N_Days', 'Age', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper', \n",
    "                    'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin', 'Stage']\n",
    "    \n",
    "    # Use KNN Imputer to fill missing numeric values\n",
    "    knn_imputer = KNNImputer(n_neighbors=5)\n",
    "    df[numeric_cols] = knn_imputer.fit_transform(df[numeric_cols])\n",
    "    \n",
    "    # Standardize numeric features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Preprocess the training data\n",
    "X_train = preprocess_data(train_df.drop(['Status', 'id'], axis=1))\n",
    "y_train = train_df['Status']\n",
    "\n",
    "# Encode target variable as numeric\n",
    "le_status = LabelEncoder()\n",
    "y_train = le_status.fit_transform(y_train)\n",
    "\n",
    "# Balance the training dataset using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning of the RandomForest model\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [10, 20],       # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5], # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['sqrt'],    # Number of features to consider when looking for the best split\n",
    "    'bootstrap': [True]          # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search for hyperparameter tuning using cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # Number of folds in cross-validation\n",
    "    scoring='neg_log_loss',  # Scoring metric for evaluation\n",
    "    n_jobs=-1  # Use all available processors\n",
    ")\n",
    "\n",
    "# Fit the grid search to the balanced training data\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Retrieve the best model and parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Calculate the log loss of the best model\n",
    "best_log_loss = -grid_search.best_score_\n",
    "print(f\"Best Log Loss: {best_log_loss}\")\n",
    "\n",
    "# Preprocess the test data\n",
    "X_test = preprocess_data(test_df.drop(['id'], axis=1), is_train=False)\n",
    "\n",
    "# Generate probability predictions for the test data\n",
    "pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# Create a submission DataFrame with the predictions\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Status_C': pred_proba[:, 0],  # Probability for class 'C'\n",
    "    'Status_CL': pred_proba[:, 1], # Probability for class 'CL'\n",
    "    'Status_D': pred_proba[:, 2]  # Probability for class 'D'\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Predictions saved to submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
